[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this site is to help foster open science in linguistics (FOSIL). The early 2010’s saw the reproducibility crisis take hold of the psychological sciences. As a consequence, there’s been a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques, now referred to as open science, have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields, such as linguistics. Important considerations often overlooked in the wake of the open science movement deal with (1) how linguists actually learn open science practices and (2) how senior researchers can train the next generation of linguists. Few, if any, researchers have had explicit instruction on the practices of open science as part of their professional training. Nonetheless, today’s speech researcher is expected to be up to date on the current protocols of open science in order incorporate the methodological practices aimed at improving reproducibility/replicability. The FOSIL project aims to make open science practices clear and accessible to people conducting research in the field of linguistics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fostering Open Science in Linguistics",
    "section": "",
    "text": "reproduciblecode/projects\n\n\n\n\npositionalitystatements\n\n\n\n\nregisteredreports\n\n\n\n\npreprints\n\n\n\n\npreregistration\n\n\n\n\nliterateprogramming\n\n\n\n\nopen data"
  },
  {
    "objectID": "posts/literate-programming/index.html",
    "href": "posts/literate-programming/index.html",
    "title": "Literate programming",
    "section": "",
    "text": "Literate programming refers to the integration of code and prose in a reproducible document. This practice is not yet mainstream in linguistics, although it holds several advantages as opposed to traditional reporting methods. Traditionally, statistical analysis, plots, tables, citations and captions would be created and manually and inserted into a manuscript. One potential issue with this approach is the increased probability of reported errors. For example, a recent study found that…(Roettger analysis of Labphon). A literate programming approach to manuscript creation would plausibly reduce the quantity of these errors, and it would make the correct information traceable more often. Additionally, updates to the data would be (almost) automatically integrated into a given manuscript if the necssary scripts are run again.\nThe present tutorial will provide an example of literate programming specifically for linguists by using an open dataset in linguistics and reported a mock analysis While the emphasis of this tutorial will be on creating a simple working example in Rmarkdown, it is important to note that literate programming can be applied within R to APA style manuscripts (see the Papaja package), in slideshows (see Xaringan) and in other programs entirely (qmd, python, jupitor notebooks)"
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "href": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "title": "Literate programming",
    "section": "Reporting descriptive statistics",
    "text": "Reporting descriptive statistics\nIn general all, inline reporting occurs in Rmardown between backticks, i.e., ` `. Specifically, you have to wrap the r code with `r ` to integrate it into your document. For instance, if we want to report the overall mean for the column DurationOfPrefix, we can simply put r code such as, mean(durationsGe$DurationOfPrefix) between to back ticks like this:\n\n\nThe mean duration is `r mean(durationsGe$DurationOfPrefix)`. \n\n\n\nWhich would be rendered as:\n\nThe mean duration is 0.1252515\n\nThere are several decimal points here, though! We probably don’t want that, so if we haven’t rounded the data previously, we can do so inline by using the round function:\n\n\nThe mean duration was `r round(mean(durationsGe$DurationOfPrefix), digits = 2)`. \n\n\n\nNow the code is rendered in prose as:\n\nThe mean duration was 0.13.\n\nAs you can see, this can get rather long in a hurry. Another option is to use an code chunk to calculate summary statistics and assign them to objects. Then you can simply use the objects with inline chunks. For instance, we likely also want to report how many participants are in our dataset. Let’s do this and report it in prose.\n\nCodemean_duration  <- round(mean(durationsGe$DurationOfPrefix), digits = 2)\nn_participants <- length(unique(durationsGe$Speaker))\n\n\n\n\nThere were `r n_participants` participants. \nThe mean duration was `r mean_duration`. \n\n\n\n\nThere were 132 participants. The mean duration was 0.13."
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "href": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "title": "Literate programming",
    "section": "Reporting results of statistical models",
    "text": "Reporting results of statistical models\nWe can also report the output statistical models and tests. Typically, the results of these tests can be stored in an object in R and extracted. I will provide an example with a t-test in R. First, we will run a t-test to see whether duration varies as a function of speaker sex:\n\nCodet_test_object <- t.test(DurationOfPrefix ~ Sex, data = durationsGe)\nt_test_object\n\n\n    Welch Two Sample t-test\n\ndata:  DurationOfPrefix by Sex\nt = -0.1949, df = 413.26, p-value = 0.8456\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.009955279  0.008159221\nsample estimates:\nmean in group female   mean in group male \n           0.1249141            0.1258121 \n\n\nFor a t-test, in APA guidelines we report degrees of freedom, the t-value, and the p-value. All of these are actually stored in the object we just created, and we can automate the reporting process.\nNote: The degree of freedom in this dataset are exaggerated due to the nested structure of the data and this t-test serves as an example only\nDegrees of Freedom\n\n\n`r round(t_test_object$parameter, digits = 2)`. \n\n\n\n\n413.26\n\nThe t-value\n\n\n`r round(t_test_object$statistic, digits = 2)`. \n\n\n\n\n-0.19\n\nThe p-value\n\n\n`r round(t_test_object$p.value, digits = 2)`. \n\n\n\n\n0.85\n\nAll together\n\n\nt = (`r round(t_test_object$parameter, digits = 2)`) =\n`r round(t_test_object$statistic, digits = 2)`, p = \n`r round(t_test_object$p.value, digits = 2)`.   \n\n\n\n\nt = (413.26) = -0.19, p = 0.85.\n\nt = (413.26) = -0.19, p = 0.85."
  },
  {
    "objectID": "posts/open-data/index.html",
    "href": "posts/open-data/index.html",
    "title": "Open data",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/positionality-statements/index.html",
    "href": "posts/positionality-statements/index.html",
    "title": "Positionality statements",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/preprints/index.html",
    "href": "posts/preprints/index.html",
    "title": "Preprints",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/preregistration/index.html",
    "href": "posts/preregistration/index.html",
    "title": "Preregistration",
    "section": "",
    "text": "Preregistration refers to a timestamped outline of a study which include components such as research questions, hypotheses, methods, and analysis. Preregistration differs from other open science practices such as registered reports and preprints as it is registered in a repository prior to data collection and it isn’t peer reviewed. Preregistration can vary a lot in detail; the simplest level with the least amount of detail can include just the hypothesis and a brief description of the methods, whereas more difficult levels with greater detail can include components such as writing analysis code beforehand in addition to the components from the simpler levels. More information on the different components that can be included in preregistration will be mentioned in the following sections.\n\nTimestamped outline including research questions, hypotheses, methods, and analysis\nNeeds to be before data collection\nCan be in varying levels of detail"
  },
  {
    "objectID": "posts/registered-reports/index.html",
    "href": "posts/registered-reports/index.html",
    "title": "Registered reports",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/reproducible-code-projects/index.html",
    "href": "posts/reproducible-code-projects/index.html",
    "title": "Reproducible code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/what-is-open-science/index.html",
    "href": "posts/what-is-open-science/index.html",
    "title": "What is open science?",
    "section": "",
    "text": "What is open science? Parsons et al. (2022) provide the following definition:\n\nAn umbrella term reflecting the idea that scientific knowledge of all kinds, where appropriate, should be openly accessible, transparent, rigorous, reproducible, replicable, accumulative, and inclusive, all which are considered fundamental features of the scientific endeavour. Open science consists of principles and behaviors that promote transparent, credible, reproducible, and accessible science. Open science has six major aspects: open data, open methodology, open source, open access, open peer review, and open educational resources.\n\nThat sounds wonderful, right? But you might be asking yourself why the push for Open Science? It may come as a surprise to some, but the open, transparent research practices described by Parsons et al. (2022) have not been the norm in scholarly research.\nTo properly contextualize the need for Open Science, we have to go back to the early 2010’s. Around this time, several fields of research embarked on large-scale replication projects to scrutinize some of their major findings. One example of these projects took place in psychology. This particular project tested whether they could replicate 100 influential findings (Open Science Collaboration 2015). They found the approximately 53% of the findings did not replicate. This project inspired similar large-scale replication projects in other fields, yielding similar results in economics (Camerer et al. 2016), social sciences (Camerer et al. 2018), and cancer research (Errington et al. 2021). These alarming findings are now referred to as the replication (or reproducibility) crisis. Researchers have pointed to questionable research practices (QRPs), p-hacking, HARKing, small sample sizes, poor theory, lack of transparency, etc. as factors that ultimately led to the replication crisis, though it is likely that other factors are at play.\n\nTake a second to consider your field of study. How many important findings do you think would replicate? If you were to replicate 100 of the most influential findings, how many would need to replicate for you to have confidence in your field?\n\nIn the aftermath of the replication crisis we have seen a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields. This website is dedicated to making open science practices understandable and accessible to researchers in the speech sciences from all backgrounds and at every stage, from students/early career researchers to senior researchers.\nTo this end, we have highlighted 7 areas in which speech researchers can engage in Open Science:\n\nLiterate programming\nOpen data\nPositionality statements\nPreprints\nPreregistration\nRegistered reports\nReproducible code/projects\n\nThroughout this website you will find tutorials designed to get you up and running in each of these areas so that you can engage in Open Science practices.\nSee Figure 1\n\n\n\n\n\nFigure 1: This is a caption\n\n\n\n\n\n\n\n\nReferences\n\nCamerer, Colin F, Anna Dreber, Eskil Forsell, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2016. “Evaluating Replicability of Laboratory Experiments in Economics.” Science 351 (6280): 1433–36. https://doi.org/10.1126/science.aaf091.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. “Evaluating the Replicability of Social Science Experiments in Nature and Science Between 2010 and 2015.” Nature Human Behaviour 2 (9): 637–44. https://doi.org/10.1038/s41562-018-0399-z.\n\n\nErrington, Timothy M, Maya Mathur, Courtney K Soderberg, Alexandria Denis, Nicole Perfito, Elizabeth Iorns, and Brian A Nosek. 2021. “Investigating the Replicability of Preclinical Cancer Biology.” Elife 10: e71601. https://doi.org/10.7554/eLife.71601.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. https://doi.org/10.1126/science.aac4716.\n\n\nParsons, Sam, Flávio Azevedo, Mahmoud M Elsherif, Samuel Guay, Owen N Shahim, Gisela H Govaart, Emma Norris, et al. 2022. “A Community-Sourced Glossary of Open Scholarship Terms.” Nature Human Behaviour 6 (3): 312–18. https://doi.org/10.1038/s41562-021-01269-4.\n\nCitationBibTeX citation:@online{v.casillas2023,\n  author = {Joseph V. Casillas},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJoseph V. Casillas. 2023. “What Is Open Science?” February\n21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nopen science\n\n\nreregistration\n\n\n\n\nAll about preregistration\n\n\n\n\n\n\nNov 21, 2023\n\n\nJiawei Shao, Adrija Gadamsetty, Katherine Taveras\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ninfo\n\n\n\n\nA quick primer on Open Science and reproducible research.\n\n\n\n\n\n\nFeb 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ninfo\n\n\ncoding\n\n\nliterate programming\n\n\n\n\nIntroduction to literate programming.\n\n\n\n\n\n\nFeb 20, 2023\n\n\nKyle Parrish, Isabelle Chang\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/preregistration/index.html#who-is-this-for-and-how-is-it-gonna-be-applied",
    "href": "posts/preregistration/index.html#who-is-this-for-and-how-is-it-gonna-be-applied",
    "title": "Preregistration",
    "section": "Who is this for and how is it gonna be applied?",
    "text": "Who is this for and how is it gonna be applied?\nPreregistration is an important practice in conducting open science, which anyone in academia conducting research can implement. This tutorial will be focusing on preregistration specifically for researchers in any field of linguistics. Many of the points such as “things to consider” and “How to preregister?” can be applied to other fields as well. Topics covered in this section include 1. what is preregistration? 2. Why do we conduct preregistration? 3. Things to consider to preregister 4. How to implement preregistration in linguistics? and 5. How to preregister?"
  },
  {
    "objectID": "posts/preregistration/index.html#why-do-we-do-preregistration",
    "href": "posts/preregistration/index.html#why-do-we-do-preregistration",
    "title": "Preregistration",
    "section": "Why do we do preregistration?",
    "text": "Why do we do preregistration?\nResearchers often have some degree of inherent flexibility in the process of designing and conducting research studies. This concept is also known as researcher degrees of freedom. With having the freedom to choose between various methods of collecting data and performing analyses, it can be easy to end up with false-positive results (i.e. an incorrect finding showing statistically significant result). The purpose of preregisteration is to deter individuals from conducting questionable research practices (QRPs) either intentionally or unintentionally by requiring them to document various components of the study. QRPs can lead to bias in the results, which can further lead to inaccurate conclusions. An example of QRPs which can be avoided through preregistration is HARKing or hypothesizing after the results are known. HARKing can be detrimental for research studies as it presents hypotheses determined after finding results as a hypothesis formed prior to the study. Another example of QRPs is p-hacking, where data is methodically excluded to result in a statistically significant result when there isn’t an actual effect between the variables. Preregistration avoids such practices because it forces researchers to record their hypotheses and methods prior to data collection. Researchers can also determine stopping rule and exclusion principals in advance, so that there’s less chance of p-hacking. HARKing along with p-hacking lead to scientific studies being difficult or impossible to be reproduced. Since reproducibility is an important part of the scientific process, not being able to reproduce results leads to theories building off on these papers to be questioned for their credibility. By preregistering, we can ensure that results can be replicated due to derailed laid out information about data collection procedures. There are many additional benefits to preregistering studies. Preregisteration can act as proof of confirmatory research for researchers, as it distinguishes decisions made before and after data collection. Encouraging greater level of detail in preregistration also helps researchers to focus on conceptualizing their research prior to conducting it. Having detailed preregistration also allows any issues to be discussed and sorted before data collection, which further eliminates any sources of error.\n\nDeter pele from QRPs\n\nEx. HARKing and p-hacking\nDocumenting researchers degree of freedom\n\n\nProof of confirmatory research: Distinguishes between decisions made before and after collecting data\nConceptualization stage: Very helpful because it forces researcher to plan out their studies\n\nDetermine stopping rule and exclusion in advance\nReproducibility because of detailed laid out information\n\n\nProofread: Any issues can be discussed and sorted out before data collection\n\nEliminates sources of error"
  },
  {
    "objectID": "posts/preregistration/index.html#things-to-consider",
    "href": "posts/preregistration/index.html#things-to-consider",
    "title": "Preregistration",
    "section": "Things to consider",
    "text": "Things to consider\nType of study\nJust as we previously discussed, one of the primary purposes of preregistration is to distinguish between confirmatory research and exploratory research, therefore it can be the start-point of preregistration. In addition, there are more types of study than the two we just mentioned, and it would be helpful to determine and preregister them before the beginning of the study, as it can be the methodological base for your study. Here type of study does not refer to the branches of linguistic studies or specialized areas of linguistic studies: we use it to categorize the methodology and purpose of the studies. In Figure 1 we listed some of the common types of study in linguistic research. It is worth mentioning that often one study can fit into multiple types listed in Figure 1.\n\n\n\n\nFigure 1: Need fig cap\n\n\n\n\nParts to include in preregistration\nMoving forward we are going to discuss what content could be included in preregistration. To put it simply, we can imagine it as a conference paper, or a research proposal, thus we have four components (Kathallawa et al, 2021):\n\nRQ\nHypotheses\nMethod\nAnalysis plan\n\nAgain, we’d like to stress that, it may be overwhelming to incorporate all four of them if you are one step in the practice of Open Science, so feel free to pick what might be most relevant to your study to begin with, and maybe engage more when you feel more comfortable with this practice in the future. Also, you can have maximum flexibility on the complexity of preregister each component.\nLevel of details\nA lot of concerns of putting Open Science into practice or doing preregistration are about the possible overload of “extra work”. On the contrary, preregistration should be helping us work in a more efficient manner both in the long run and in short terms. Besides, you have complete control of how much detail you want to include. The more detailed the preregistration is, the more effort you need to put into, and as a result the less work down the road. Here we only propose some of the levels of details that may help you determine how much details you can incorporate in your preregistration (Figure 2). The darker the shade, the more detailed it is (thus more work). Again, you can always incorporate different levels of details in different parts.\n\n\n\n\nFigure 2: Levels of detail"
  },
  {
    "objectID": "posts/preregistration/index.html#how-can-we-make-it",
    "href": "posts/preregistration/index.html#how-can-we-make-it",
    "title": "Preregistration",
    "section": "How can we make it?",
    "text": "How can we make it?\nThere are websites dedicated to Open Science practices. OSF is one and it provide platform and/or template we can use.\n\n\nOSF\nGithub\nAspredicted.org\nBy hand\n\n\n\n\n\nOSF\n\nStart from scratch\nStart from an existing OSF project or component\n\n\n\n\n\nPre registration involves making a plan for your research project before collecting and analyzing data. This plan can be documented and shared on Github, which is a popular web-based hosting service for version control and collaborative software development.\nHere are the steps to set up a pre registration for your research on Github:\n\nCreate a Github account: If you do not already have a Github account, create one by visiting the Github homepage and following the instructions.\nCreate a new repository: Once you are logged in to Github, you can create a new repository to store your pre registration documents. Click the “New” button in the top left corner of the screen and follow the prompts to create a new repository.\nChoose a template: Github provides several templates for different types of repositories. You can choose a template that is specifically designed for pre registration documents, such as the Open Science Framework (OSF) Preregistration template.\nAdd your pre registration documents: Once you have chosen a template, you can add your pre registration documents to the repository. These documents should include a detailed description of your research question, hypotheses, methods, and analysis plan. You can use Markdown, a lightweight markup language, to format your documents on Github.\nShare your repository: Once your pre registration documents are complete, you can share your repository with other researchers or members of the public. You can do this by sharing the link to your repository or by inviting collaborators to contribute to the project.\nUpdate your repository: As you collect and analyze data, you may need to update your pre registration documents. You can do this by making changes to your documents on Github and committing the changes to the repository.\n\nBy setting up a preregistration on Github, you can make your research more transparent and reproducible. Other researchers can review your plan and provide feedback, and you can use the repository to document any changes you make to your research plan over time.\n\n\n\nOne author creates the pre-registration.\nParticipating authors are emailed, requesting approval.\nIf all approve, it is saved but remains private until an author makes it public; or remains private forever.(Why?)\nAuthors may share an anonymous version of the pre-registration with reviewers.\nIf made public, the final .pdf (sample) is automatically stored in the web-archive.\n\n\n\nWrite, timestamp + freeze, and then check yourself\nTo set up a pre registration for your research from scratch on paper, you can follow these steps:\n\nDefine your research question and hypotheses: Start by identifying the research question you are trying to answer and any hypotheses you have about the expected results.\nSelect your variables and measures: Identify the independent and dependent variables in your study and describe the measures you will use to operationalize these variables.\nDetermine your sample size and recruitment strategy: Specify the number of participants you plan to recruit and describe how you will recruit them.\nOutline your research design: Describe the research design you will use to address your research question, such as a between-subjects or within-subjects design.\nSpecify your data analysis plan: Describe the statistical analyses you plan to use to test your hypotheses, including any planned exploratory analyses and methods to handle missing data.\nPlan for ethical considerations: Address any ethical considerations in your study, such as obtaining informed consent from participants, ensuring confidentiality and privacy, and handling any potential risks or harms.\nConsider any potential limitations: Anticipate any potential limitations of your study, such as sampling bias or measurement error.\nWrite up your pre registration plan: Once you have completed these steps, write up your pre registration plan in a clear and concise manner on paper. Be sure to include all relevant information, such as your research question, hypotheses, variables and measures, sample size and recruitment strategy, research design, data analysis plan, ethical considerations, and potential limitations.\n\n\n\n\nTo read more about preregistration in linguisticis: https://www.degruyter.com/document/doi/10.1515/ling-2019-0048/html?lang=en\nReference Kathawalla, U. K., Silverstein, P., & Syed, M. (2021). Easing into open science: A guide for graduate students and their advisors. Collabra: Psychology, 7(1)"
  }
]